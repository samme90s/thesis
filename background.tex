\section{Theoretical Background}

Data typically fall into two primary categories: structured and unstructured. Structured data are characterized by a well-defined, predefined format, often organized in tables where rows represent entities and columns represent specific attributes. Examples include relational databases, spreadsheets containing employee records with distinct fields (ID, name, department), or financial reports with clearly defined columns for dates, categories, and values. This inherent organization makes structured data readily amenable to querying and analysis using standard tools.

In contrast, unstructured data lack a predefined data model or organizational schema. This category represents a large majority of the data generated today and includes diverse sources such as emails, text documents, social media content, images, videos, and operational logs such as Work Orders (WOs) relevant to this study. A typical WO, for instance, may contain free-form text describing maintenance procedures, lists of materials, location information, and customer details, none of which conform to a rigid structure \cite{ibm2023work}. Due to this variability and lack of explicit organization, unstructured data cannot be easily stored or analyzed using traditional tabular methods and presents unique challenges \cite{ibm2025datadiff}.

Despite the analytical challenges, unstructured text data often contains substantial valuable information. The significant volume and complexity of this data requires the use of automated techniques to process, categorize, and extract meaningful insights. Within the field of Natural Language Processing (NLP), text classification stands out as a fundamental method developed precisely for this purpose. It is the task of automatically assigning predefined labels or categories to text documents based on their content. Applying text classification to resources like WOs, emails, or reports helps impose a useful structure, enabling better organization and downstream analysis.

Historically, the task of text classification has been approached using various machine learning (ML) methodologies. Early techniques often involved rule-based systems or classical supervised algorithms such as Logistic Regression and Naive Bayes. A critical prerequisite for applying these traditional algorithms to text was feature engineering. Since these models typically require numerical input, feature engineering involved processes to identify and extract relevant textual characteristics (e.g., word frequencies via Term Frequency-Inverse Document Frequency (TF-IDF), presence of specific n-grams, Bag-of-Words representations) and convert them into a structured vector format suitable for the ML model \cite{bing2011mining}.


However, the early techniques often fall short in capturing language nuances, context details, and the ambiguity in unstructured text. More recently, advances in natural language processing (NLP) have led to the development of large language models (LLMs) based on transformer architectures such as GPT and BERT. These models use self-attention to focus on important parts of the text and capture deep meaning by understanding relationships between words. There are even newer versions that add reasoning capabilities, which aim to improve decision-making in text classification. Learning from vast amounts of pre-trained data and use self-attention to track relationships between words, which significantly improves their ability to understand and predict next word context. For example, while traditional ML models focus on manually extracting features, modern LLMs such as the previously mentioned GPT and BERT can adapt to various types of text with minimal human intervention such as pre processing and structuring. Supporting this development, recent research has shown that LLMs -- especially when fine-tuned for particular domains -- exhibit not only advanced language understanding but also reasoning capabilities that can further improve text classification performance \cite{huang2024classification, andersson2024ikea, merritt2022transformer, nazyrova2024medical, wang2024classifiers}, capabilities central to the comparisons explored in this work (RQ1, RQ2, RQ3).

One of the most significant advantages of large language models over traditional approaches is their ability to generalize to new tasks using \textbf{zero-shot}, \textbf{one-shot}, and \textbf{few-shot} learning \cite{brown2020language}. These concepts refer to how much prior labeled data a model needs to perform a task. Zero-shot learning allows an LLM to classify text without being explicitly trained on any labeled examples. The model uses pre-trained knowledge to infer the most likely category based on a prompt describing the task. One-shot learning improves upon this by giving the model just one labeled example before making the classification. Finally, few-shot learning further enhances accuracy by providing multiple labeled examples in the prompt, allowing the model to generalize more effectively without requiring full retraining.

Switching focus to a machine learning technique such as recurrent neural networks or long short-term memory (LSTMs) shows capability in handling sequences of words and remembering long distances between related words. This makes it easier for the model to understand context without needing manual feature design. This technique was introduced in the late 90's and is far less complex and resource consuming than the latter transformer technique and is still considered a state-of-the-art algorithm \cite{wang2024classifiers, hochreiter1997long}. However, training and testing an RNN och LSTM model still requires a significant amount of resources when using a large dataset.

These datasets often require some processing involving actions such as bag of words (BoW) and term frequency-inverse document frequency (TF-IDF). Briefly explained, \cite{murel2024bagofwords} bag of words involves collecting the frequency of words in documents; more specifically, it's a feature extraction technique that models text data by creating an unstructured collection of all words in a document. The collection solely represents how often the words appear while ignoring grammar, word order, and context. Building upon this concept is TF-IDF, which can be described as a variation that further accounts for word frequency not just within one document, but across a whole corpus (a large collection of writings of a specific kind or on a specific subject), effectively giving more weight to terms that are significant to a specific document compared to common words found everywhere.

Although as Nazyrova et al. \cite{nazyrova2024medical} focuses on the medical application area within text classification, the principles are directly applicable to our context. Traditionally, companies rely on manual processing of WOs, a practice that is both labor-intensive and error prone \cite{li2024work}.


