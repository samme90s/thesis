\section{Introduction}

This paper introduces the different aspects of the research and to provide the main
scope. It will describe large language models (LLMs) and their applications in
text classification. We will collaborate with UPTILT that delivers an application
to customers within the service business, solving the delivery of invoices and
offers to the customer by tracking materials, hourly work and more. They have
provided us with the necessary data which has been redacted to ensure anonymity
and privacy. We will foremost discuss the importance of classifying work orders (WOs),
but also provide a general conclusion on the topic and contribute to the field
of text classification and natural language processing (NLP) using LLMs.

\subsection{Background}

In many industries today, working with and handling large quantities of
structured and unstructured data is extremely important. One example is text classification
which labels text based on their content. Traditionally, machine learning (ML) methods
have been used for this purpose, but recently, LLMs have shown potential posing generative
capabilities, along with understanding and reasoning within language(s) \cite{huang2024}
\cite{zhang2024}.

Training an ML model means analyzing the content of the text and identifying features
that are relevant, so computer systems can, for example, use this technique for
identifying spam and filtering documents \cite{dalal2011}. Comparing this approach
to an already widely trained LLM model, which does not require the same amount
of manual labor and configuration.

LLMs are a subgroup of AI that work on the knowledge of next word context and
are often utilized in the context of allowing the user to prompt it with
instructions or questions. They utilize a much larger pre-trained knowledge compared
to machine learning, which often specializes in a specific domain and type of
data. Furthermore, they can analyze data and recognize patterns with minimal
human interaction, and makes them highly effective in applications like NLP \cite{andersson2024}.

WOs is a document that outlines the details of a maintenance task. This data
comes in the form of text and can through proper utilization be the key
component when categorizing using LLMs. WOs most commonly contains information regarding
the material required to complete such task, but also the geographic location, customer
etc. Today, many companies still rely on manual processing, which often leads to
mistakes \cite{ibm2023} \cite{li2024}. Throughout our work, we will focus on
providing a better solution than the current manual processing by using LLMs to
classify work orders.

\subsubsection{Related Work}

Huang and He \cite{huang2024} explain the cost of manual labor when it comes to tagging
and categorizing text. Furthermore, the fine-tuning and choice of parameters can
influence the final behavior of the trained ML model. They explain how the
latest LLMs have showcased "remarkable reasoning performance across a wide range
of NLP tasks". We aim to follow this trail and further analyze the efficiency and
performance of categorizing text within the context of WOs.

\bigskip
Recent advances in LLMs have shown that they can be fine-tuned to effectively classify
structured data. For example, gpt-4 and llama-2 have shown remarkable
performance in text classification \cite{zhang2024}. We will be discussing and
evaluating the efficiency and accuracy of using LLMs to classify structured WOs,
unlike previous studies, which focuses more on general NLP tasks. Our paper gives
an insight into whether they can be used with correct prompting to classify WOs.

\bigskip
Current research has demonstrated that transformer-based models (a neural
network architecture, meaning it learns by tracking relationships between words \cite{merritt2022}),
such as BERT and other domain-specific variants, significantly improve text
classification processes through transfer learning and fine-tuning
\cite{nazyrova2024}. While Nazyrova et al. focuses on medical text
classification and our focus lies within WO classification, their findings on the
topic of fine-tuning LLMs is relevant for our paper and its research.

\subsection{Research Questions}

This thesis aims to answer the following research question:

\bigskip
\textit{RQ1: Can a higher accuracy when using large language models for text classification
of work orders be achieved on an unstructured dataset compared to a traditional machine
learning model with structured data?}

\bigskip
\textit{RQ2: Can a higher accuracy when using reasoning large language models for
text classification of work orders be achieved on an unstructured dataset compared
to a non-reasoning large language model?}