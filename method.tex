\section{Method}
% https://www.scribbr.com/dissertation/methodology/
% https://www.youtube.com/watch?v=2MqLFH7CalQ
%
% It should include:
%
% The type of research you conducted
% How you collected and analyzed your data
% Any tools or materials you used in the research
% How you mitigated or avoided research biases
% Why you chose these methods
%
% Your methodology section should generally be written in the PAST TENSE!
In our work on text classification, it was important to directly measure how changes in our methods influenced performance. That is why we chose a controlled experiment --- as it let us tweak one or more factors (for example, feature extraction or model parameters) while keeping all other conditions the same. This controlled setting made it easier to observe and measure the impact on key performance indicators, like classification accuracy or F1-score, using statistical tests. Because we obtained numerical measurements from our experiments, our approach is inherently quantitative.
Wohlin et al. \cite{wohlin2000} explain that controlled experiments provide a clear way to investigate cause-and-effect relationships. Compared to surveys or case studies --- which may mix in effects from uncontrolled factors --- a controlled experiment minimizes external influences. This allows us to be more confident that any changes in the performance of our text classification system are due to the specific modifications we introduced rather than random variation.

% --------------------------------------------
\subsection{Experiment design}
% Step 1:
% Methodological approach:
%
% Research problem:
% Gain more understanding of the research problem.
% Type of data?
% How data was collected?
%
% An experiment is not a proof => it can reject a hypothesis but not prove it
% (only make it more likely).
%
% Experiments with a single independent variable are easier to analyze.
%
% We often need a baseline for an experiment to make sense (provide knowledge).


% Update this and explain that the data was split and how we used ground truth in comparison to the other split parts etc... also remove that the part that states there may be sensitive data...
The data was used to train and evaluate different models for the purpose of this research. The experiment was conducted using anonymized WOs, but may still contain sensitive information. Therefore, a thorough cleaning process was performed to ensure that no sensitive information was present in the dataset once the experiment was conducted. The dataset was split into training and evaluation (test) subsets to ensure that the models were not overfitting the data using the decimals of pi as seeds.

The prompt was constructed using a domain expert within the service business underlying important parts and making sure the prompt contains uses the correct language and words. Furthermore, this guaranteed that the iterations throughout the methodology adhered to the specific domain requirements --- making sure that the results stayed consistent.


% Continuing with SETUP subsubsection... (as a part of the experiment design)
% As example:
% - The machine used
% - The software used (versions!)
% - What types of measurement tools where used
%   (again versions, unless it is already a part of the software)
% - Explain the experiment approach and how it was conducted.
% - The more details the better!
%
% Add sources/references here to support our choices!

\subsection{Dataset pre-processing}
% Explain how the data is pre-processed
% Example remove stop words, punctuation, etc.
% Tokenize for NLTK
% Include explaination of where our scripts are located.
%
% Use python script for this.
% Potential subheading:
% \subsubsection{Text cleaning}
% \subsubsection{Word segementation}
% \subsubsection{Stop words removal}

\subsection{Models \& configurations}
% Specify the LLMs and ML models/algorithms used (e.g., GPT-4o, Deepseek, Naive Bayes).
%
% Explain why these models were chosen and how they are relevant to the research question.
% Describe whether the models are pre-trained, fine-tuned, or used with prompt engineering.
% Explain any hyperparameter tuning performed (e.g., learning rate, batch size).
% Discuss the computational resources required (e.g., GPUs, cloud services).
%
% Explain how we aim to label/classify the work orders here.
%
% Use references to support our choices here!

\subsubsection{Independent variables}
% Not sure if this is correct outlining the variables like this but may be useful
% to get the general idea of what we are working with:
%
% A variable is anything that can change or be changed => any factor that can be
% manipulated, controlled for, or measured in an experiment.
%
% Independent variables:
% These are factors that you can manipulate in an experiment.
% Our hypothesis is that respective independent variable causes a direct effect on
% the dependent variable(s).
%
% Can be seen as inputs.
\begin{center}
    \begin{tabular}{| l  |l |}
        Dataset & The UPTILT dataset sent to pre-processor and models\\
 Pre-processing&\\
        Models & The different models used (both LLMs and ML algorithms). \\
 Model configuration&\\
 Question &The prompt\\
    \end{tabular}
\end{center}

\subsubsection{Dependent variables}
% Dependent variables:
% These are factors that you can observe or measure. As we change the independent variable(s),
% we observe what happens to the dependent variable(s).
%
% Can be seen as outputs.
\begin{center}
    \begin{tabular}{| l | l |}
        Accuracy            & The overall correctness of the model.           \\
        Precision           & The correctness of positive predictions.        \\
        Recall              & The ability to identify all relevant instances. \\
        F1 score            & A combined metric of precision and recall.      \\
        Execution time (ms) & The computational efficiency of each model.     \\
    \end{tabular}
\end{center}

\subsubsection{Hypotheses}
% (hypotheis: singular | hypotheses: plural)
% Should be a statement that can be proven or disproven. Thus, it must be testable...
% It should be rejectable as in, it should be easy to say whether it is true or false.
\textcolor{blue}{See RQ1 and RQ2 here and build the hypotheses based on these.}

\subsubsection{Predictions}
% Based on the hypotheses, what do we expect to see?

% --------------------------------------------
\subsection{Data collection}
% Step 2:
% Methods of data collection:
%
% The sampling method or critera
% The tools, procedures, and materials
% How variables were measured
%
% Explain the table structure here as well!
% See Oxana's model/image in Slack.
\textcolor{blue}{Explain the tools and methods used to collect the data for our
result. Furthermore, explain the variables that were measured. See comments...}

% --------------------------------------------
\subsection{Data analysis}
% Step 3:
% Describe the methods of analysis
% (i.e. how you processed and analyzed the data):
%
% Quantitative data:
% - Data preparation
% - Software
% - Statistical methods
%
% Analysis based of:
% - Language
% - Images
% - Interpretations
% - Themes and Patterns
%
% A rigorous skepticism should be a part of every experiment:
% - Is this really a correct (fair) comparison?
% - Can we really draw these conclusions based on this experiment?
% - Have we taken all independent variables into account?
% - Are the measurements correct?
\textcolor{blue}{Explain the methods used to analyze the collected data. See comments...}

% --------------------------------------------
\subsection{Research biases (reliability and validity)}
% Step 4:
% Evaluate and justify methodological choices:
%
% Why you chose these particular methods?
% Why other methods were not suitable for your objectives?
% How this approach contributes new knowledge or understanding?