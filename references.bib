@article{garces2025leveraging,
title = {Leveraging language models for automated distribution of review notes in animated productions},
journal = {Neurocomputing},
volume = {626},
pages = {129620},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.129620},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225002929},
author = {Diego Garcés and Matilde Santos and David Fernández-Llorca},
keywords = {Movie production, Review notes, Text Classification, Large Language Models (LLM), Natural Language Processing},
abstract = {During the production of an animated film, professionals at the animation studio prepare thousands of notes. These notes describe improvements and corrections identified by supervisors and directors during daily meetings where the film’s progress is reviewed. After each meeting, these notes are manually distributed to the appropriate departments that need to address them. Due to the manual nature of this process, many notes are not assigned correctly, and the identified issues are not addressed, reducing the final quality of the film. This article describes and compares several approaches to automatically distribute notes using multi-label text classification with different language models (LM). Implemented methods include logistic regression models, encoder-only models such as the BERT family, and decoder-only models such as Llama 2 including fine-tuning and QLoRA techniques. Training and inference were conducted on a local RTX-3090. The results of the different techniques have been compared, achieving a maximum average accuracy of 0.83 and an f1-score of 0.89 with the fine-tuned Multilingual BERT model. This demonstrates the validity of these models for multi-label text classification, as well as their usefulness in a hitherto unexplored area such as animation studios.}
}

@INPROCEEDINGS{niraula2024multi,
  author={Niraula, Nobal and Ayhan, Samet and Chidambaram, Balaguruna and Whyatt, Daniel},
  booktitle={2024 AIAA DATC/IEEE 43rd Digital Avionics Systems Conference (DASC)}, 
  title={Multi-Label Classification with Generative Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  keywords={Training;Large language models;Supervised learning;Training data;Aerospace electronics;Data models;Safety;Multi-label Classification;Natural language pro- cessing;Large Language Models;Machine learning},
  doi={10.1109/DASC62030.2024.10748883}
}

@online{murel2024bagofwords,
    author       = {Murel, Jacob and Kavlakoglu, Eda},
    title        = {What is bag of words?},
    year         = {2024},
    month        = {January},
    day          = {19},
    url          = {https://www.ibm.com/think/topics/bag-of-words},
    urldate      = {2025-04-02},
    organization = {IBM}
}

@mastersthesis{sahu2025language,
    author  = {Sahu, Kaustab Chandra},
    title   = {Language Models for Classification of Patient Text Messages},
    school  = {Reykjavík University},
    year    = {2025},
    month   = {January},
    note    = {Thesis for Master of Science degree},
    address = {Reykjavík, Iceland}
}

@article{sarker2021machine,
    author = {Iqbal H. Sarker},
    title = {Machine Learning: Algorithms, Real-World Applications and Research Directions},
    journal = {Springer},
    year = {2021},
    doi = {https://doi.org/10.1007/s42979-021-00592-x}
}

@article{sutskever2014sequence,
    author = {Ilya Sutskever and Oriol Vinyals and Quoc V. Le},
    title = {Sequence to sequence learning with neural networks},
    journal = {arXiv},
    year = {2014},
    doi = {https://doi.org/10.48550/arXiv.1409.3215}
}

@article{jamshidi2024effective,
    author = {Saman Jamshidi and Mahin Mohammadi and Saeed Bagheri and Hamid Esmaeili Najafabadi and Alireza Rezvanian and Mehdi Gheisari and Mustafa Ghaderzadeh and Amir Shahab Shahabi and Zongda Wu},
    title = {Effective text classification using BERT, MTM LSTM, and DT},
    journal = {ScienceDirect},
    year = {2024},
    doi = {https://doi.org/10.1016/j.datak.2024.102306}
}

@article{brown2020language,
    author = {Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
    title = {Language Models are Few-Shot Learners},
    journal = {arXiv},
    year = {2020},
    doi = {https://doi.org/10.48550/arXiv.2005.14165}
}

@article{touvron2023llama,
    author = {Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
    title = {LLaMA: Open and Efficient Foundation Language Models},
    journal = {arXiv},
    year = {2023},
    doi = {https://doi.org/10.48550/arXiv.2302.13971}
}

@article{moller2024parrot,
    author = {Anders Giovanni Møller and Jacob Aarup Dalsgaard and Arianna Pera and Luca Maria Aiello},
    title = {The Parrot Dilemma: Human-Labeled vs. LLM-augmented Data in Classification Tasks},
    journal = {arXiv},
    year = {2024},
    doi = {https://doi.org/10.48550/arXiv.2304.13861}
}

@article{betianu2024dallmi,
    author = {Miruna Bețianu and Abele Mălan and Marco Aldinucci and Robert Birke and Lydia Chen},
    title = {DALLMi: Domain Adaption for LLM-Based Multi-label Classifier},
    journal = {Springer},
    year = {2024},
    doi = {https://doi.org/10.1007/978-981-97-2259-4_21}
}

@article{oh2024language,
    author = {Changdae Oh and Minhoi Park and Sungjun Lim and Kyungwoo Song},
    title = {Language model-guided student performance prediction with multimodal auxiliary information},
    journal = {ScienceDirect},
    year = {2024},
    doi = {https://doi.org/10.1016/j.eswa.2024.123960}
}

@article{dalal2011classification,
    author = {Mita K. Dalal and Mukesh A. Zaveri},
    title = {Automatic Text Classification: A Technical Review},
    journal = {International Journal of Computer Applications},
    year = {2011},
    doi = {https://doi.org/10.5120/3358-4633}
}

@article{huang2024classification,
    author = {Chen Huang and Guoxiu He},
    title = {Text Clustering as Classification with LLMs},
    journal = {arXiv},
    year = {2024},
    doi = {https://doi.org/10.48550/arXiv.2410.00927}
}

@article{li2024work,
    author = {Yongkui Li and Yan Liu and Jiansong Zhang and Lingyan Cao and Qinyue Wang},
    title = {Automated analysis and assignment of maintenance work orders using natural language processing},
    journal = {ScienceDirect},
    year = {2024},
    doi = {https://doi.org/10.1016/j.autcon.2024.105501}
}

@article{wang2024classifiers,
    author = {Zhiqiang Wang and Yiran Pang and Yanbin Lin},
    title = {Smart Expert System: Large Language Models as Text Classifiers},
    journal = {arXiv},
    year = {2024},
    doi = {https://doi.org/10.48550/arXiv.2405.10523}
}

@article{hochreiter1997long,
    author = {Sepp Hochreiter and Jürgen Schmidhuber},
    title = {Long Short-Term Memory},
    journal = {Neural computation},
    year = {1997},
    doi = {https://doi.org/10.1162/neco.1997.9.8.1735}
}

@article{nazyrova2024medical,
    author = {Nodira Nazyrova and Salma Chahed and Thierry Chausalet and Miriam Dwek},
    title = {Leveraging large language models for medical text classification: a hospital readmission prediction case},
    journal = {IEEE},
    year = {2024},
    doi = {https://doi.org/10.1109/ICPRS62101.2024.10677826}
}

@mastersthesis{andersson2024ikea,
    author = {Linnéa Andersson},
    title = {Transaction classification using a large language model: A study on whether large language models can be used to make accurate classifications of financial transactions within IKEA Supply},
    school = {Umeå University},
    year = {2024},
    url = {https://www.diva-portal.org/smash/get/diva2:1871473/FULLTEXT04.pdf}
}

% ONLINE (non-scientific) SOURCES
% -------------------------------
@online{ibm2023work,
    author = {IBM},
    title = {What is a Work Order?},
    year = {2023},
    urldate = {2025-01-29}, 
    url = {https://www.ibm.com/think/topics/work-order}
}

@online{ibm2025datadiff,
    author = {Jonker Alexandra and Gomstyn Alice},
    title = {Structured vs. unstructured data: What's the difference?},
    year = {2025},
    urldate = {2025-03-05},
    url = {https://www.ibm.com/think/topics/structured-vs-unstructured-data}
}

@online{merritt2022transformer,
    author = {Merritt},
    title = {What Is a Transformer Model?},
    year = {2022},
    urldate = {2025-02-02}, 
    url = {https://blogs.nvidia.com/blog/what-is-a-transformer-model/}
}

% BOOKS
% -------------------------------
@book{wohlin2000software,
    author = {Claes Wohlin and Per Runeson Martin Höst and Magnus C. Ohlsson and Björn Regnell and Anders Wesslén},
    title = {Experimentation in Software Engineering},
    publisher = {Springer},
    year = {2000},
    isbn = {978-3-642-29043-5}
}

@book{bing2011mining,
    author = {Bing Liu},
    title = {Web Data Mining: Exploring Hyperlinks, Contents, and Usage Data},
    publisher = {Springer},
    year = {2011},
    isbn = {978-3-642-19460-3}
}

@book{bird2009nlp,
    author = {Steven Bird and Ewan Klein and Edward Loper},
    title = {Natural Language Processing with Python},
    publisher = {O'Reilly Media},
    year = {2009},
    isbn = {978-0-596-51649-9}
}

@inproceedings{Lang95
,author = "Ken Lang"
,title = "Newsweeder: Learning to filter netnews"
,year = 1995
,booktitle = "Proceedings of the Twelfth International Conference on Machine Learning"
,pages = "331-339"
}

@inproceedings{Joachims1998,
  author    = {Thorsten Joachims},
  title     = {Text Categorization with Support Vector Machines: Learning with Many Relevant Features},
  booktitle = {Proceedings of the 10th European Conference on Machine Learning (ECML '98)},
  year      = {1998},
  pages     = {137--142},
  publisher = {Springer},
  address   = {Berlin, Heidelberg},
}