\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{xcolor}
\usepackage{hyperref}

\title{Student Project Proposal}
\author{Hampus Tuisku \and Samuel Svensson}
\date{\today}

\begin{document}
\maketitle

\section{Introduction}

\subsection{LNU Supervisor}
Oxana Lundstr√∂m

\subsection{Supervision status according to student}

\begin{itemize}
      \item [ ] Currently working with (ongoing project)
      \item [ ] Agreed, but not started
      \item [x] Wish to work with (or unclear of status)
      \item [ ] No preference, help me find one
\end{itemize}

\subsection{Cooperative Partners}

UPTILT

One meeting, we agreed to work together.
Continuous discussion using virtual and physical applications.

\subsection{Preliminary Title}

Work Order Categorization using Text Classification Machine Learning compared to LLM

\subsection{Elevator Pitch}



\subsection{Steps/Milestones/Actions}

\begin{enumerate}
      \item Research other similar projects within ML (Machine Learning) using Naive Bayes,
            SVC or Random Forest -models alternatively LLM (Large Language Model) for text
            classification/categorization. Then summarize, position and motivate our standing to
            this research gap.
      \item Create two questions we aim to answer in the thesis, where the respective author
            has more responsibility for one.
      \item Create methodology on how we aim to come to a conclusion using the documents gathered.
      \item Use SciKit/NLTK pre-processed using Word Frequency in conjunction with Python
            to create models to gather statistics on the categorization of WO (Work Order).
      \item Use LLM to categorize the WO and compare the categorization statistics
            with the ML models.
      \item Compare our statistics such as their precision,
            effectiveness and cost with previous documents mentioned in the background etc.,
            to reason why one option is better than the others for WO categorization.
\end{enumerate}

\subsection{Risks}

\begin{itemize}
      \item The complexity behind ML (Naive Bayes, SVC and Random Forest) and LLM when
            we have limited knowledge due to the extensive area and constant updates to LLM.
      \item With too many models to analyze within the time limit, the analysis becomes
            shallow and lacks depth, even though we may require a substantial number of models
            to reach a comprehensive conclusion.
      \item The training of the ML models -- requiring pre-categorized work orders
\end{itemize}

\subsection{Background and Motivations}

\section{References}

 [1]

\end{document}
