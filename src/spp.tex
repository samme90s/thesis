% Fundamental framework for your document structure
\documentclass{article}
% Reduces overfull boxes
\usepackage{microtype}
% Needed for your colored text boxes in the elevator pitch (\textcolor{green}{...} etc.)
\usepackage{xcolor}
% Required for PDF hyperlinks and proper PDF metadata (especially important when combined with natbib)
\usepackage{hyperref}
% Crucial for your citation management (\cite commands) and bibliography style
\usepackage[numbers,sort&compress]{natbib}

\title{Student Project Proposal}
\author{Samuel Svensson \and Hampus Tuisku}
\date{\today}

\begin{document}
\maketitle

\section{Pre-Introduction}

\subsection{LNU Supervisor}
Oxana Lundström

\subsection{Supervision status according to student}

\begin{itemize}
      \item [ ] Currently working with (ongoing project)
      \item [ ] Agreed, but not started
      \item [x] Wish to work with (or unclear of status)
      \item [ ] No preference, help me find one
\end{itemize}

\subsection{Cooperative Partners}

We will cooperate with UPTILT, who are currently working on delivering a program
to customers within the service business.
They aim to deliver a product meant to keep track of materials and hourly work
to automate the delivery of invoices and offers to the customer.

We have continous discussions and meetings with the company.

\subsection{Preliminary Title}

Automated Text Categorization for work orders using LLM

\subsection{Elevator Pitch}

Automatic text categorization is an important step when analyzing textual data,
and the approach of Large Language Models (LLMs) have emerged as an alternative
to the traditional Machine Learning (ML).
ML often requires balanced, labeled datasets for effective training
and demands significant manual effort, in contrast to LLMs that
leverages pre-trained contextual knowledge.
We aim to use LLMs to categorize work order (WO) titles and descriptions
through a rigorous method,
and evaluate the impact of different prompts and strategies to find
an effective solution to the subject at hand.

\subsection{Steps/Milestones/Actions}

\begin{enumerate}
      \item Find related work.
      \item Create two questions related to our different strategies used
            when using the LLM (this is for each of us to have an area of
            greater responsibility).
      \item Define method (be creative here to find interresting approaches
            to our problem).
      \item Conduct experiment.
      \item Analyze results.
\end{enumerate}

\subsection{Risks}

\begin{itemize}
      \item No previous experience in creating a method, so we will have to rely on our
            supervisor here.
      \item Finding creative and concrete ways to test the effectiveness and accuracy.
\end{itemize}

\section{Introduction}

\subsection{Background}

In many industries today, working with and handling large quantities of structured and unstructured data is
extremely important.
One example is categorization of WOs in fields such as manufacturing, logistics and maintenance.
Traditionally, ML methods such as Support Vector Machines (SVM), Random Forest and Naive Bayes classifiers
have been used for text classification tasks.
Automating this process can be done using one of the former models when training for such task.
The training means analyzing the content of the text and identifying features that are relevant,
so computer systems can, for example, use this technique for identifying spam and filtering documents \cite{dalal2011}.
Compared to the former approaches that requires manual training and configuration,
this paper aims to find a more effective solution when dealing with text classification
and exploring the usage of LLM in relation with WOs.

\subsubsection{Large Language Models}

LLMs are a subgroup of AI that work on the knowledge of next word context and are often utilized
in the context of allowing the user to prompt it with instructions or questions.
LLMs utilize pre-trained knowledge, unlike traditional ML models, which require manual training,
balanced datasets and human intervention.
LLMs can analyze data and recognize patterns with minimal human intervention.
This makes LLMs highly effective in applications like Natural Language Processing (NLP) \cite{andersson2024},
and in our case classification of WOs.

\subsubsection{Automated Text Categorization of Work Orders}

WOs is a document that outlines the details of a maintenance task.
This data comes in the form of text and properly utilized can be the key component when categorizing using LLMs.
It most commonly contains information regarding the material required to complete such task,
but also the geographic location, customer etc.
Today, many companies still rely on manual processing, which often leads to mistakes.
Throughout our work we will focus on providing a better solution than the current manual processing,
by using LLMs \cite{ibm2023} \cite{li2024}.

Assigning text to pre-defined categories is the key of text categorization,
sometimes named classification, but we will stick to the former.
These may include areas such as topic labeling or news categorization.
It has been further proven that the latest LLMs currently posses great generative capabilities,
along with understanding and reasoning within language(s) as previously mentioned.
They therefore have become more efficient than humans when it comes to NLP tasks \cite{zhang2024}.

\subsubsection{Related Work}

Huang and He \cite{huang2024} explain the cost of manual labor when it comes to tagging and categorizing text.
Furthermore, the fine-tuning and choice of parameters can influence the final behaviour of the trained ML model.
They explain how the latest LLMs have showcased "remarkable reasoning performance across a wide range of
NLP tasks".
We aim to follow this trail and further analyze the effeciency and performance of categorizing text within the
context of WOs.

Recent advances in LLMs have shown that they can be fine-tuned to effectively classify structured data.
For example, GPT-4, LLaMA 2, and ChatGLM 2 have shown remarkable performance in text classification \cite{zhang2024}.
Our research in this paper will be to discuss and evaluate the efficiency and accuracy of using LLMs
to text classify structured WOs.
Unlike previous studies, which focuses more on general NLP tasks,
our paper gives an insight into whether LLMs can be used with correct prompting to classify WOs.

Recent research has demonstrated that transformer-based models, such as
Bidirectional Encoder Representations from Transformers (BERT) and other domain-specific variants,
significantly improve text classification processes through transfer learning and fine-tuning \cite{Nazyrova2024}.
While this study focus on medical text classification, its findings in on LLM fine-tuning is releveant for our
paper and its research.
% SAM: Kanske bara BERT istället för hela namnet för att göra det mer lättläst?
% Dessutom behövs skrivas om för bättre flöde.

% HAMPUS: Denna text tyckte jag blev okej

% SAM: Snälla kolla om de källor jag lade till är korrekt, se "references.bib".
% Hittade ju bara den ena källan som du länkade till längst ner.
% Vi behöver nämligen lägga till källorna först i "references.bib" för att kunna
% använda dem som \cite{key}.

\bibliographystyle{IEEEtran}
\bibliography{references}

\end{document}
