\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{xcolor}
\usepackage{hyperref}

\title{Student Project Proposal}
\author{Hampus Tuisku \and Samuel Svensson}
\date{\today}

\begin{document}
\maketitle

\section{Pre-Introduction}

\subsection{LNU Supervisor}
Oxana Lundström

\subsection{Supervision status according to student}

\begin{itemize}
      \item [ ] Currently working with (ongoing project)
      \item [ ] Agreed, but not started
      \item [x] Wish to work with (or unclear of status)
      \item [ ] No preference, help me find one
\end{itemize}

\subsection{Cooperative Partners}

UPTILT

One meeting, we agreed to work together.
Continuous discussion using virtual and physical applications.

\subsection{Preliminary Title}

Work Order Categorization using Text Classification Machine Learning compared to LLM

\subsection{Elevator Pitch}

\subsubsection{Hampus}

Pitch by Hampus:

Background:
Text classification is a key task to perform by using traditional Machine Learning (ML) algorithms,
but it typically requires labeled data and model training for it to work. However, the using
of Large Language Models (LLMs) may be a more efficient solution.

Challenge:
The challenge with traditional ML algorithms is that the algorithm needs a balanced dataset to
perform well. This in comparison to LLMs, which already has knowledge within broad areas.

Action:
Our goal with this paper is to see if categorizing titles for work orders can be done by
using LLMs and if it can be a more efficient way instead of using traditional ML algorithms.

Evaluation:
The results will contain information about the data we worked with...

\subsubsection{Samuel}

Idé:

Automatiserad text kategorisering med hjälp av llm eller ml.

Om det redan finns text kategorisering i samband med LLM (vilket det borde finnas).
Bör vi kika på vilka ML modeller dem jämför med så kanske vi kan göra något liknande fast jämföra
resultatet med en annan opensource model istället för GPT.o4.

Pitch 2:

Background:
Automated text categorization using Machine Learning (ML) is a standard today, but with the new
Large Language Models (LLM) it may become more beneficial. - vague (det är det vi redan bör undersöka)

Challenge:
The problem is that ML often needs balanced datasets to be trained efficiently and perform well,
in contrast to LLM that often already has a broader knowledge within and outside the subject at hand,
thus requiring no manual training. - styrka

Action:
We aim to provide insight in wether or not a ML model is required, when it requires more manual
intervention compared to the LLM.


Pitch 1:

Background:
Machine Learning (ML) including Large Language Models (LLM) is an active topic regarding text
categorization. It is a valuable asset removing the need for most manual labor within the area.

Challenge:
The problem is that ML often needs balanced datasets to be trained efficiently and perform well,
in contrast to LLM such as the GPT models that often already has a broader knowledge within and
outside the subject at hand.

Action:
We therefore, intend to study one model from each respective area and compare their results,
to gain insight in the subject if it is worth using LLM instead of ML.
- (remove) Furthermore, see if we can combine both techniques to provide a better accuracy.

Evaluation:
The evaluation will contain these types of data... bla bla bla.

\subsubsection{Combined}

Background:
Text classification/categorization is widely used in conjunction with Machine Learning.
(Kolla om LLM används till textklassificering).

Challenge:
Chosing a ML algorithm for text classification/categorization requires a balanced dataset to
perform well, compared to LLM, which already has a broad knowledge within many areas.

Action:
We aim to see if categoring titles for work orders can be done using an LLM, which is not
specialized for this, compared to using a traditional ML algorithm and avoiding manual training
of model.

Evaluation:
The results, ..., will give insight to the efficiency of using LLM compared to traditional ML,
and if it is a better solution and optimization (ease-of-use) for developers.

\subsection{Steps/Milestones/Actions}

\begin{enumerate}
      \item Research other similar projects within ML (Machine Learning) using Naive Bayes,
            SVC or Random Forest -models alternatively LLM (Large Language Model) for text
            classification/categorization. Then summarize, position and motivate our standing to
            this research gap.
      \item Create two questions we aim to answer in the thesis, where the respective author
            has more responsibility for one.
      \item Create methodology on how we aim to come to a conclusion using the documents gathered.
      \item Use SciKit/NLTK pre-processed using Word Frequency in conjunction with Python
            to create models to gather statistics on the categorization of WO (Work Order).
      \item Use LLM to categorize the WO and compare the categorization statistics
            with the ML models.
      \item Compare our statistics such as their precision,
            effectiveness and cost with previous documents mentioned in the background etc.,
            to reason why one option is better than the others for WO categorization.
\end{enumerate}

\subsection{Risks}

\begin{itemize}
      \item The complexity behind ML (Naive Bayes, SVC and Random Forest) and LLM when
            we have limited knowledge due to the extensive area and constant updates to LLM.
      \item With too many models to analyze within the time limit, the analysis becomes
            shallow and lacks depth, even though we may require a substantial number of models
            to reach a comprehensive conclusion.
      \item The training of the ML models -- requiring pre-categorized work orders
\end{itemize}

\section{Introduction}

\subsection{Background}

\subsubsection{Text Classification}
Explain the area...

\subsubsection{Related Work}
Reveal other studies and their conclusions,
poisiton ourselves and then motivate...

\section{References}

 [1]

\end{document}
