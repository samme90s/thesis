\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{xcolor}
\usepackage{hyperref}

\title{Student Project Proposal}
\author{Hampus Tuisku \and Samuel Svensson}
\date{\today}

\begin{document}
\maketitle

\section{Introduction}

\subsection{LNU Supervisor}
Oxana Lundström

\subsection{Supervision status according to student}

\begin{itemize}
      \item [ ] Currently working with (ongoing project)
      \item [ ] Agreed, but not started
      \item [x] Wish to work with (or unclear of status)
      \item [ ] No preference, help me find one
\end{itemize}

\subsection{Cooperative Partners}

UPTILT

One meeting, we agreed to work together.
Continuous discussion using virtual and physical applications.

\subsection{Preliminary Title}

Work Order Categorization using Text Classification Machine Learning compared to LLM

\subsection{Elevator Pitch}

\subsubsection{Hampus}
This paper explores the question to find for more efficient and cost-effective approaches to text classification for
organizing unstructured data. It will look at the topics such as the performance and efficiency of traditional
machine learning algorithms compared to large language models (LLMs) when working with text-classification tasks in work-order systems.

The challenge this paper is trying to solve for companies is to show when It's worth to use LLM and when it's not, and
then instead use traditional machine learning models to solve their text-classification problems. It's a difficult question to answer
because it depends on a number of factors, for example what system the company is using and how complex the data is.

This paper will compare traditional machine learning algorithms. The paper will also compare machine learning algorithms
to LLM's and also see if we can combine the different techniques to fully optimize and find a solution that is the most cost-effective
and efficient.

We will in this paper compare the different algorithms and look at the data we got and look which is the most effective when it comes to speed
and how reliable the output is.


New suggestion:

This paper explores how to use text-classification by using Large Language Models (LLMs) and how to implement it in a work order system.

The challenge this

\subsubsection{Samuel}

Idé:

Automatiserad text kategorisering med hjälp av llm eller ml.

Om det redan finns text kategorisering i samband med LLM (vilket det borde finnas).
Bör vi kika på vilka ML modeller dem jämför med så kanske vi kan göra något liknande fast jämföra
resultatet med en annan opensource model istället för GPT.o4.

Pitch 2:

Background:
Automated text categorization using Machine Learning (ML) is a standard today, but with the new
Large Language Models (LLM) it may become more beneficial. - vague (det är det vi redan bör undersöka)

Challenge:
The problem is that ML often needs balanced datasets to be trained efficiently and perform well,
in contrast to LLM that often already has a broader knowledge within and outside the subject at hand,
thus requiring no manual training. - styrka

Action:
We aim to provide insight in wether or not a ML model is required, when it requires more manual
intervention compared to the LLM.


Pitch 1:

Background:
Machine Learning (ML) including Large Language Models (LLM) is an active topic regarding text
categorization. It is a valuable asset removing the need for most manual labor within the area.

Challenge:
The problem is that ML often needs balanced datasets to be trained efficiently and perform well,
in contrast to LLM such as the GPT models that often already has a broader knowledge within and
outside the subject at hand.

Action:
We therefore, intend to study one model from each respective area and compare their results,
to gain insight in the subject if it is worth using LLM instead of ML.
- (remove) Furthermore, see if we can combine both techniques to provide a better accuracy.

Evaluation:
The evaluation will contain these types of data... bla bla bla.

\subsubsection{Combined}



\subsection{Steps/Milestones/Actions}

\begin{enumerate}
      \item Research other similar projects within ML (Machine Learning) using Naive Bayes,
            SVC or Random Forest -models alternatively LLM (Large Language Model) for text
            classification/categorization. Then summarize, position and motivate our standing to
            this research gap.
      \item Create two questions we aim to answer in the thesis, where the respective author
            has more responsibility for one.
      \item Create methodology on how we aim to come to a conclusion using the documents gathered.
      \item Use SciKit/NLTK pre-processed using Word Frequency in conjunction with Python
            to create models to gather statistics on the categorization of WO (Work Order).
      \item Use LLM to categorize the WO and compare the categorization statistics
            with the ML models.
      \item Compare our statistics such as their precision,
            effectiveness and cost with previous documents mentioned in the background etc.,
            to reason why one option is better than the others for WO categorization.
\end{enumerate}

\subsection{Risks}

\begin{itemize}
      \item The complexity behind ML (Naive Bayes, SVC and Random Forest) and LLM when
            we have limited knowledge due to the extensive area and constant updates to LLM.
      \item With too many models to analyze within the time limit, the analysis becomes
            shallow and lacks depth, even though we may require a substantial number of models
            to reach a comprehensive conclusion.
      \item The training of the ML models -- requiring pre-categorized work orders
\end{itemize}

\subsection{Background and Motivations}

\section{References}

 [1]

\end{document}
